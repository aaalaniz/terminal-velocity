An algorithm is a finite sequence of well-defined, computer-implementable instructions. They are typically used to solve a class of problems or to perform a computation. Algorithms are always unambiguous and are used as specifications for performing calculations and data processing. They can be expressed in many kinds of notation, including natural language, pseudocode, and flowcharts. Analysis of algorithms is a major discipline in computer science. It involves finding the resources, such as time and storage, needed to execute them. Big O notation is often used to describe the limiting behavior of a function.
